{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc52f571",
   "metadata": {},
   "source": [
    "# TFG - Fórmula 1 - Test ranking NN\n",
    "\n",
    "Autor: Manuel Ventura\n",
    "\n",
    "Test de la red neuronal obtenida para predecir rankings, utilizando la métrica *Kendall's Tau*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0442621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b734b0a",
   "metadata": {},
   "source": [
    "## Test model over full dataset (regression model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_csv('data_ready/LEARNING_DF_NORMAL.csv')\n",
    "grid = pd.read_csv('data_ready/2023_grid_data.csv')\n",
    "date_parse_list = ['date', 'fp1_date', 'fp2_date', 'fp3_date', 'quali_date', 'sprint_date']\n",
    "races = pd.read_csv('f1db_csv/races.csv', na_values=[\"\\\\N\"], parse_dates=date_parse_list)\n",
    "drivers = pd.read_csv('f1db_csv/drivers.csv')\n",
    "model = tf.keras.models.load_model('models/nn_model_final.h5')\n",
    "scaler = joblib.load('models/minmaxscaler_nn_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3f46883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "races = races.loc[races['year'] >=2000].copy()\n",
    "scores = []\n",
    "\n",
    "for index, race in races.iterrows():\n",
    "    if race.date>=pd.Timestamp.now():\n",
    "        continue\n",
    "    # Get race\n",
    "    df = df_old.loc[(df_old['year']==race['year']) & (df_old['round']==race['round'])].copy()\n",
    "    \n",
    "    # Transform data\n",
    "    df['grid'] = df['grid'].clip(upper=20)\n",
    "    df['position'] = df['position'].clip(upper=20)\n",
    "    columns_to_scale = ['year', 'age', 'experience', 'driversPointsBeforeRace', 'constPointsBeforeRace']\n",
    "    df[columns_to_scale] = scaler.transform(df[columns_to_scale])\n",
    "    columns_to_replace = ['weather_warm', 'weather_cold', 'weather_dry', 'weather_wet', 'weather_cloudy']\n",
    "    df[columns_to_replace] = df[columns_to_replace].replace(1,20)\n",
    "    y = df['position']\n",
    "    drivers = df['driverId']\n",
    "    constructors = df['constructorId']\n",
    "    circuits = df['circuitId']\n",
    "    X = df.drop(['driverId', 'constructorId', 'circuitId', 'position'], axis=1)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    preds = model.predict([drivers, constructors, circuits, X], verbose = 0)\n",
    "    preds_df = pd.DataFrame()\n",
    "    preds_df['driverId'] = df['driverId']\n",
    "    preds_df['predictions'] = preds\n",
    "    preds_df = preds_df.merge(drivers, how='inner', on='driverId')\n",
    "    preds_df = preds_df.sort_values(by=['predictions'])\n",
    "    df = df.sort_values(by=['position'])\n",
    "    scores.append(scipy.stats.kendalltau(preds_df['driverId'], df['driverId']).correlation)\n",
    "    \n",
    "avg_kendall = sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6295c3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7825871262551288"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_kendall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116967c",
   "metadata": {},
   "source": [
    "## Test model over full dataset (categorical model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd948b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_csv('data_ready/LEARNING_DF_NORMAL.csv')\n",
    "grid = pd.read_csv('data_ready/2023_grid_data.csv')\n",
    "date_parse_list = ['date', 'fp1_date', 'fp2_date', 'fp3_date', 'quali_date', 'sprint_date']\n",
    "races = pd.read_csv('f1db_csv/races.csv', na_values=[\"\\\\N\"], parse_dates=date_parse_list)\n",
    "drivers = pd.read_csv('f1db_csv/drivers.csv')\n",
    "model = tf.keras.models.load_model('models/nn_model_categorical_nolookup.h5')\n",
    "scaler = joblib.load('models/minmaxscaler_categorical_nolookup.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3a8b09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "races = races.loc[races['year'] >=2000].copy()\n",
    "scores = []\n",
    "\n",
    "for index, race in races.iterrows():\n",
    "    if race.date>=pd.Timestamp.now():\n",
    "        continue\n",
    "    # Get race\n",
    "    df = df_old.loc[(df_old['year']==race['year']) & (df_old['round']==race['round'])].copy()\n",
    "    \n",
    "    # Transform data\n",
    "    df['grid'] = df['grid'].clip(upper=20)\n",
    "    df['position'] = df['position'].clip(upper=20)\n",
    "    columns_to_scale = ['grid', 'year', 'round', 'age', 'experience', 'driversPointsBeforeRace', 'constPointsBeforeRace']\n",
    "    df[columns_to_scale] = scaler.transform(df[columns_to_scale])\n",
    "    y = df['position']\n",
    "    drivers = df['driverId']\n",
    "    constructors = df['constructorId']\n",
    "    circuits = df['circuitId']\n",
    "    X = df.drop(['driverId', 'constructorId', 'circuitId', 'position'], axis=1)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    preds = model.predict([drivers, constructors, circuits, X], verbose = 0)\n",
    "    df_preds = pd.DataFrame()\n",
    "    df_preds['driverId'] = df['driverId']\n",
    "    df_preds['prediction'] = np.argmax(preds, axis=1)+1\n",
    "    df_preds = df_preds.merge(drivers, how='inner', on='driverId')\n",
    "    df_preds = df_preds.sort_values(by=['prediction'])\n",
    "    df = df.sort_values(by=['position'])\n",
    "    scores.append(scipy.stats.kendalltau(df_preds['driverId'], df['driverId']).correlation)\n",
    "    \n",
    "avg_kendall = sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7a78a811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9825513935541836"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_kendall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c0e9a",
   "metadata": {},
   "source": [
    "## Test model over full dataset (categorical model with lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc94d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_csv('data_ready/LEARNING_DF_NORMAL.csv')\n",
    "grid = pd.read_csv('data_ready/2023_grid_data.csv')\n",
    "date_parse_list = ['date', 'fp1_date', 'fp2_date', 'fp3_date', 'quali_date', 'sprint_date']\n",
    "races = pd.read_csv('f1db_csv/races.csv', na_values=[\"\\\\N\"], parse_dates=date_parse_list)\n",
    "drivers = pd.read_csv('f1db_csv/drivers.csv')\n",
    "constructors = pd.read_csv('f1db_csv/constructors.csv')\n",
    "circuits = pd.read_csv('f1db_csv/circuits.csv')\n",
    "model = tf.keras.models.load_model('models/nn_model_categorical')\n",
    "scaler = joblib.load('models/minmaxscaler_categorical.pkl')\n",
    "\n",
    "\n",
    "df_old = df_old.merge(drivers[['driverId','driverRef']], how='inner', on='driverId')\n",
    "df_old = df_old.merge(constructors[['constructorId','constructorRef']], how='inner', on='constructorId')\n",
    "df_old = df_old.merge(circuits[['circuitId','circuitRef']], how='inner', on='circuitId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b5322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "races = races.loc[races['year'] >=2000].copy()\n",
    "scores = []\n",
    "\n",
    "for index, race in races.iterrows():\n",
    "    if race.date>=pd.Timestamp.now():\n",
    "        continue\n",
    "    # Get race\n",
    "    df = df_old.loc[(df_old['year']==race['year']) & (df_old['round']==race['round'])].copy()\n",
    "    \n",
    "    # Transform data\n",
    "    df['grid'] = df['grid'].clip(upper=20)\n",
    "    df['position'] = df['position'].clip(upper=20)\n",
    "    columns_to_scale = ['grid', 'year', 'round', 'age', 'experience', 'driversPointsBeforeRace', 'constPointsBeforeRace']\n",
    "    df[columns_to_scale] = scaler.transform(df[columns_to_scale])\n",
    "    df = df.drop(['driverId', 'constructorId', 'circuitId'], axis=1)\n",
    "    drivers = df['driverRef']\n",
    "    constructors = df['constructorRef']\n",
    "    circuits = df['circuitRef']\n",
    "    X = df.drop(['driverRef', 'constructorRef', 'circuitRef', 'position'], axis=1)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    preds = model.predict([drivers, constructors, circuits, X], verbose=0)\n",
    "    df_preds = pd.DataFrame()\n",
    "    df_preds['driverRef'] = df['driverRef']\n",
    "    df_preds['prediction'] = np.argmax(preds, axis=1)+1\n",
    "    df_preds = df_preds.merge(drivers, how='inner', on='driverRef')\n",
    "    df_preds = df_preds.sort_values(by=['prediction'])\n",
    "    df = df.sort_values(by=['position'])\n",
    "    scores.append(scipy.stats.kendalltau(df_preds['driverRef'], df['driverRef']).correlation)\n",
    "\n",
    "avg_kendall = sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "81c6da3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796374382586873"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_kendall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255abe8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
